{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "name": "ADA2021_exercise2_AmandaMyntti.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mmanteli/Applications-of-Data-Analysis-2021/blob/main/ADA2021_exercise2_AmandaMyntti.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kwcxxIpAbRGl"
      },
      "source": [
        "Amanda Myntti <br>\n",
        "Student number 514011 <br>\n",
        "February, 10th, 2021  <br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KqOVry4GbRGs"
      },
      "source": [
        "# Exercise 2 | TKO_2096 Application of Data Analysis 2021"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNDuypuTbRGt"
      },
      "source": [
        "#### Prediction of the metal ion content from multi-parameter data <br>\n",
        "- Use K-Nearest Neighbor Regression with euclidean distance to predict total metal concentration (c_total), concentration of Cadmium (Cd) and concentration of Lead (Pb), for each sample using number of neighbors k = 3.<br> <br>\n",
        "\n",
        "    - You may use Nearest Neighbor Regression from https://scikit-learn.org/stable/modules/neighbors.html\n",
        "    - The data should be standarized using z-score.\n",
        "    - Implement your own Leave-One-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb). \n",
        "    - Implement your own Leave-Replicas-Out cross-validation and calculate the C-index for each output (c_total, Cd, Pb).\n",
        "    - Return your solution as a Jupyter Notebook file (include your full name in the file name).\n",
        "    - Submit to moodle your solution on **Wednesday 10 of February** at the latest."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eSzrjmzl58uO"
      },
      "source": [
        "### Comments by the student\r\n",
        "This was a nice exercise, and it was much easier to do than the 1st one, simply because there we're more instructions on the template. I learned a lot, and I found a better way to do splits than in the last exercise! :) \r\n",
        "\r\n",
        "There are a few things I'd like to point out about my code:\r\n",
        "\r\n",
        "*   My computer died on Friday and I lost all my progress (I had done about 30-40%) and I had to start again on Monday with my new laptop. Luckily I did finish this on time, but now I do not have time to optimize the code at all and the leave-replicas-out algorithm is *really* slow. There might be some spaghetty parts in the code, too. Sorry about that!\r\n",
        "*   Also for the same reason I had to copy a lot of my old code, meaning I use the terms \"training and validation sets\" in the code, but speak about \"training and test sets\". I do not have time (or do I dare) to make changes in the code anymore, since if I break something now, I'll never correct in on time! So for all of this, consider validation == test.\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8aE6T0obRGu"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5Pu_lGfYbRGu"
      },
      "source": [
        "#In this cell import all libraries you need. For example: \n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import standardize\n",
        "from sklearn.neighbors import KNeighborsRegressor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCA0W_IcvXZc"
      },
      "source": [
        "## Data preprosessing\r\n",
        "I'll first take a look at the data, find replicas, and z-score standardize the features I'll be using."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyDRS9h_bRGv"
      },
      "source": [
        "### Read and visualize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sfUH5bsbRGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "479972b7-a076-4542-89e8-ca436c38469e"
      },
      "source": [
        "# read the data\n",
        "water_data = pd.read_csv('Water_data.csv')\n",
        "\n",
        "# printing info, because it gives us more info than the size of the dataframe\n",
        "water_data.info()\n",
        "\n",
        "# printing the first five rows\n",
        "water_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 225 entries, 0 to 224\n",
            "Data columns (total 6 columns):\n",
            " #   Column   Non-Null Count  Dtype  \n",
            "---  ------   --------------  -----  \n",
            " 0   c_total  225 non-null    int64  \n",
            " 1   Cd       225 non-null    float64\n",
            " 2   Pb       225 non-null    float64\n",
            " 3   Mod1     225 non-null    int64  \n",
            " 4   Mod2     225 non-null    int64  \n",
            " 5   Mod3     225 non-null    int64  \n",
            "dtypes: float64(2), int64(4)\n",
            "memory usage: 10.7 KB\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c_total</th>\n",
              "      <th>Cd</th>\n",
              "      <th>Pb</th>\n",
              "      <th>Mod1</th>\n",
              "      <th>Mod2</th>\n",
              "      <th>Mod3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>126430</td>\n",
              "      <td>2604</td>\n",
              "      <td>6996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>20597</td>\n",
              "      <td>271</td>\n",
              "      <td>138677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>24566</td>\n",
              "      <td>269</td>\n",
              "      <td>161573</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>105732</td>\n",
              "      <td>971</td>\n",
              "      <td>132590</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>57774</td>\n",
              "      <td>5416</td>\n",
              "      <td>93798</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   c_total     Cd      Pb    Mod1  Mod2    Mod3\n",
              "0     2000  800.0  1200.0  126430  2604    6996\n",
              "1       35   14.0    21.0   20597   271  138677\n",
              "2       35   14.0    21.0   24566   269  161573\n",
              "3       35   35.0     0.0  105732   971  132590\n",
              "4      100   20.0    80.0   57774  5416   93798"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 778
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcHUlI9GbRGv"
      },
      "source": [
        "#### To show understanding of the data, answer the following questions:\n",
        "- How many different mixtures of Cadmium (Cd) and Lead (Pb) were measured? <br>\n",
        "- How many total concentrations (c_total) were measured? <br>\n",
        "- How many mixtures have less than 4 replicas? <br>\n",
        "- How many mixtures have 4 or more replicas? Print out c_total, Cd and Pb for those concentrations.<br>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6FFj6Z8FbRGv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 889
        },
        "outputId": "ad15a375-0ab3-4a45-e3ec-0cd3857b7abc"
      },
      "source": [
        "# print the length of the whole data to get the number of all measurements\r\n",
        "print(\"Number of total entries: \",len(water_data['c_total']))\r\n",
        "\r\n",
        "# To get the number of unique measurements, I'll make another dataframe that has \r\n",
        "# all the unique measurements in one row, and the last column is the fequency\r\n",
        "water_data_freq = water_data.groupby(['c_total','Cd', 'Pb']).size().reset_index(name='Freq')\r\n",
        "\r\n",
        "# can be printed if needed\r\n",
        "#print(\"Data according to frequency:\")\r\n",
        "#display(water_data_freq)\r\n",
        "\r\n",
        "# the length of this dataframe is the number of unique measurements\r\n",
        "print(\"Distinct measurements of Cd and Pb: \", len(water_data_freq))\r\n",
        "\r\n",
        "# define a few sub dataframes based on the frequency\r\n",
        "water_low_freq = water_data_freq[water_data_freq.Freq < 4]\r\n",
        "water_high_freq = water_data_freq[water_data_freq.Freq >= 4]\r\n",
        "\r\n",
        "# print the number according to their lengths => number of measurement with  \r\n",
        "# corresponding number of replicas\r\n",
        "print(\"Number of measurements with less than 4 replicas: \",len(water_low_freq) )\r\n",
        "print(\"Number of measurements with 4 or more replicas: \",len(water_high_freq) )\r\n",
        "\r\n",
        "# lastly, print out the high freq values\r\n",
        "print(\"\") # for clarity\r\n",
        "print(\"Values for high frequency replicas:\")\r\n",
        "display(water_high_freq)\r\n",
        "\r\n",
        "# I printed this too to see their frequencies, all 3\r\n",
        "#display(water_low_freq)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of total entries:  225\n",
            "Distinct measurements of Cd and Pb:  67\n",
            "Number of measurements with less than 4 replicas:  43\n",
            "Number of measurements with 4 or more replicas:  24\n",
            "\n",
            "Values for high frequency replicas:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c_total</th>\n",
              "      <th>Cd</th>\n",
              "      <th>Pb</th>\n",
              "      <th>Freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>50.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>50</td>\n",
              "      <td>10.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>50</td>\n",
              "      <td>20.0</td>\n",
              "      <td>30.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>50</td>\n",
              "      <td>30.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>50</td>\n",
              "      <td>40.0</td>\n",
              "      <td>10.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>50</td>\n",
              "      <td>50.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>70</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>70</td>\n",
              "      <td>14.0</td>\n",
              "      <td>56.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>70</td>\n",
              "      <td>28.0</td>\n",
              "      <td>42.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>70</td>\n",
              "      <td>42.0</td>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>70</td>\n",
              "      <td>56.0</td>\n",
              "      <td>14.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>70</td>\n",
              "      <td>70.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>100.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>100</td>\n",
              "      <td>40.0</td>\n",
              "      <td>60.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>100</td>\n",
              "      <td>60.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>100</td>\n",
              "      <td>80.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>100</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>200</td>\n",
              "      <td>0.0</td>\n",
              "      <td>200.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>200</td>\n",
              "      <td>40.0</td>\n",
              "      <td>160.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>200</td>\n",
              "      <td>80.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>200</td>\n",
              "      <td>120.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>200</td>\n",
              "      <td>160.0</td>\n",
              "      <td>40.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>200</td>\n",
              "      <td>200.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    c_total     Cd     Pb  Freq\n",
              "19       50    0.0   50.0     4\n",
              "20       50   10.0   40.0     4\n",
              "21       50   20.0   30.0     4\n",
              "22       50   30.0   20.0     4\n",
              "23       50   40.0   10.0     4\n",
              "24       50   50.0    0.0     4\n",
              "25       70    0.0   70.0     4\n",
              "26       70   14.0   56.0     4\n",
              "27       70   28.0   42.0     4\n",
              "28       70   42.0   28.0     4\n",
              "29       70   56.0   14.0     4\n",
              "30       70   70.0    0.0     4\n",
              "31      100    0.0  100.0     4\n",
              "32      100   20.0   80.0     4\n",
              "33      100   40.0   60.0     4\n",
              "34      100   60.0   40.0     4\n",
              "35      100   80.0   20.0     4\n",
              "36      100  100.0    0.0     4\n",
              "37      200    0.0  200.0     4\n",
              "38      200   40.0  160.0     4\n",
              "39      200   80.0  120.0     4\n",
              "40      200  120.0   80.0     4\n",
              "41      200  160.0   40.0     4\n",
              "42      200  200.0    0.0     4"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nkHYipX9iCn3"
      },
      "source": [
        "From this analysis it is easy to see that there are two kinds of datapoints: some have 3 replicas (43 points) and others 4 (24 points). This equals the number of all datapoints, 43x3 + 4x24 = 225. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xtZkiwCvbRGw"
      },
      "source": [
        "### Standardization of the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEf_6qpsbRGw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "8c2063f0-c60d-4dcd-aa71-8ff252e8a1ed"
      },
      "source": [
        "# I used the ready made Z-score standardisation from mlxtend.preprocessing\n",
        "water_data[['Mod1','Mod2','Mod3']] = standardize(water_data[['Mod1','Mod2','Mod3']])\n",
        "\n",
        "# display the first 5 values to make sure everything worked\n",
        "display(water_data.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>c_total</th>\n",
              "      <th>Cd</th>\n",
              "      <th>Pb</th>\n",
              "      <th>Mod1</th>\n",
              "      <th>Mod2</th>\n",
              "      <th>Mod3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2000</td>\n",
              "      <td>800.0</td>\n",
              "      <td>1200.0</td>\n",
              "      <td>0.166505</td>\n",
              "      <td>-0.508756</td>\n",
              "      <td>-1.499041</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>35</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-0.892616</td>\n",
              "      <td>-0.701641</td>\n",
              "      <td>0.685861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>35</td>\n",
              "      <td>14.0</td>\n",
              "      <td>21.0</td>\n",
              "      <td>-0.852896</td>\n",
              "      <td>-0.701806</td>\n",
              "      <td>1.065760</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>35</td>\n",
              "      <td>35.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.040629</td>\n",
              "      <td>-0.643767</td>\n",
              "      <td>0.584863</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100</td>\n",
              "      <td>20.0</td>\n",
              "      <td>80.0</td>\n",
              "      <td>-0.520568</td>\n",
              "      <td>-0.276268</td>\n",
              "      <td>-0.058789</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   c_total     Cd      Pb      Mod1      Mod2      Mod3\n",
              "0     2000  800.0  1200.0  0.166505 -0.508756 -1.499041\n",
              "1       35   14.0    21.0 -0.892616 -0.701641  0.685861\n",
              "2       35   14.0    21.0 -0.852896 -0.701806  1.065760\n",
              "3       35   35.0     0.0 -0.040629 -0.643767  0.584863\n",
              "4      100   20.0    80.0 -0.520568 -0.276268 -0.058789"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iQGDYIKQeMz"
      },
      "source": [
        "### Separating the data\r\n",
        "Lastly, I'll separate the data to features (X) and labels (y). We're trying to predict total, Cd and Pb concentrations from the measurements Mod1, Mod2 and Mod3. \r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XYfTUZx_RJuM"
      },
      "source": [
        "# features (Mod1, Mod2, Mod3)\r\n",
        "X = water_data[['Mod1','Mod2','Mod3']]\r\n",
        "\r\n",
        "\r\n",
        "# labels (Cd, Pb)\r\n",
        "y = water_data[['c_total','Cd','Pb']]\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VUdaWomvoIq"
      },
      "source": [
        "## Algorithm for the Concordance index and data splitting\r\n",
        "\r\n",
        "Next I'll define a function for the concordance index, that  measures if the model was able to rank the data points in the same order as the true outputs. Also train-test splits for leave-one-out CV and leave-replicas-out CV are defined here."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2VMYd_XjbRGw"
      },
      "source": [
        "### C-index code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHvj0EjhbRGx"
      },
      "source": [
        "def cindex(true_labels, pred_labels):\n",
        "  \"\"\"Returns C-index between true labels and predicted labels\"\"\"  \n",
        "  \n",
        "  # set data collection: concordant pairs and all pairs\n",
        "  N = 0\n",
        "  counts = 0.0\n",
        "\n",
        "  # go over all the pairs (a triangle):\n",
        "\n",
        "  for i in range(len(true_labels)):\n",
        "    for j in range(i+1, len(pred_labels)):\n",
        "\n",
        "      # if the true labels are not the same \n",
        "      if (true_labels[i] != true_labels[j]):\n",
        "\n",
        "        # add 1 to one pairs\n",
        "        counts +=1.0\n",
        "\n",
        "        # make the comparison given in the extra material, N += 1 if it's true\n",
        "        if (true_labels[i] < true_labels[j] and pred_labels[i] < pred_labels[j]) or (true_labels[j] < true_labels[i] and pred_labels[j] < pred_labels[i]):\n",
        "          N += 1\n",
        "        \n",
        "  # c index is the concordant pairs / all pairs\n",
        "  cindx = N/counts\n",
        "\n",
        "  return cindx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "onHg-0kZbRGx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00764673-9f50-4b67-8e26-cc71bb5575a1"
      },
      "source": [
        "#test cindex function with following values\n",
        "#true_labels = [-1, 1, 1, -1, 1]\n",
        "#predictions = [0.60, 0.80, 0.75, 0.75, 0.70]\n",
        "\n",
        "# testing with the extra material data, answer should be 0.67\n",
        "# I tested with this because I know the correct answer to this\n",
        "true_labels = [7.1,2.3,5.4,1.8]\n",
        "predictions = [7.4,3.4,8.5,3.9]\n",
        "\n",
        "cindx = cindex(true_labels, predictions)\n",
        "print(cindx)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6666666666666666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nbhrg-FXOeHe"
      },
      "source": [
        "The c-index function gives the correct result with the data provided in the extra material."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EzXNz1k8bRGx"
      },
      "source": [
        "### Splitting functions\r\n",
        "These functions are really similar, but are written quite differently. Also, the LRO-function is really slow, since it makes new dataframes everytime. I tried to reduce the runtime by simply modifying each dataframe, not creating a new one all the time, but that lead to an error, and I do not have time debug it now. The function works just like I intended it to, it is simply slow."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Im-lf_nIbRGx"
      },
      "source": [
        "#Include here all the functions that you need to run in the data analysis part.\r\n",
        "\r\n",
        "def LOO_folds(X,y,idx):\r\n",
        "  \"\"\" \r\n",
        "  Splits the given data into training and validation sets, with |val| = 1.\r\n",
        "  Input: features X, labels y, index of LOO idx\r\n",
        "  Returns: X_train, X_val, y_train, y_val\r\n",
        "  \"\"\"\r\n",
        "  # for training sets, simply drop the one row\r\n",
        "  X_train = X.drop(idx)\r\n",
        "  y_train = y.drop(idx)\r\n",
        "\r\n",
        "  # for validation sets, drop everything else but the one row\r\n",
        "  # make a list to help\r\n",
        "  lista = np.arange(0,len(X))\r\n",
        "  lista2 = np.delete(lista, idx)\r\n",
        "  # drop indices on the list\r\n",
        "  X_val = X.drop(lista2)\r\n",
        "  y_val = y.drop(lista2)\r\n",
        "\r\n",
        "  # return the sets\r\n",
        "  return X_train, X_val, y_train, y_val\r\n",
        "\r\n",
        "\r\n",
        "def LRO_folds(X,y,idx,droplist):\r\n",
        "  \"\"\" \r\n",
        "  Splits the given data into training and validation sets so that all replicas\r\n",
        "  of the datapoint are in the same validation set.\r\n",
        "  Input: features X, labels y, index of first datapoint, \r\n",
        "  droplist = list of indices that have alreafy been in a validation set\r\n",
        "  Returns: X_train, X_val, y_train, y_val, updated droplist\r\n",
        "  \"\"\"\r\n",
        "\r\n",
        "  # save values on the idx row\r\n",
        "  c_tot = y.iat[idx,0]\r\n",
        "  cd = y.iat[idx,1]\r\n",
        "  pb = y.iat[idx,2]\r\n",
        "  \r\n",
        "  # copy X and y to train and val sets\r\n",
        "  X_train = X\r\n",
        "  X_val = X\r\n",
        "  y_train = y\r\n",
        "  y_val = y\r\n",
        "\r\n",
        "  # loop over all the points\r\n",
        "  for i in range(len(X)):\r\n",
        "    # if there's a replica in index i\r\n",
        "    if (y.iat[i,0] == c_tot and y.iat[i,1] == cd and y.iat[i,2] == pb):\r\n",
        "      # drop it from training data\r\n",
        "      X_train = X_train.drop(i)\r\n",
        "      y_train = y_train.drop(i)\r\n",
        "      # add the index to droplist, so that we'll not redo it\r\n",
        "      droplist.append(i)\r\n",
        "    else:\r\n",
        "      # it's not a replica; drop it from validation\r\n",
        "      X_val = X_val.drop(i)\r\n",
        "      y_val = y_val.drop(i)\r\n",
        "\r\n",
        "  # return the sets\r\n",
        "  return X_train, X_val, y_train, y_val,droplist\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTkkm1aNbRGx"
      },
      "source": [
        "## Results for Leave-One-Out cross-validation\r\n",
        "Here I'll make predictions to each LOO-split, and after that find the concordance index between the predicted labels and the real labels."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwD_f8rObRGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "280b427b-7729-4e38-b5f5-150a16f27378"
      },
      "source": [
        "# make vectors to store data (name accordingly)\r\n",
        "c_total_predicted_labels = []\r\n",
        "cd_predicted_labels = []\r\n",
        "pb_predicted_labels = []\r\n",
        "\r\n",
        "c_total_true_labels = []\r\n",
        "cd_true_labels = []\r\n",
        "pb_true_labels = []\r\n",
        "\r\n",
        "\r\n",
        "# loop over all the data\r\n",
        "for i in range(len(water_data)):\r\n",
        "\r\n",
        "  # make train-test split, in the test(here val) data there is only 1 point\r\n",
        "  X_train, X_val, y_train, y_val = LOO_folds(X,y,i)\r\n",
        "\r\n",
        "  # train knn with 3 neighbors and euclidean metric\r\n",
        "  knn = KNeighborsRegressor(n_neighbors=3, metric='euclidean')\r\n",
        "  # fit the train data\r\n",
        "  knn.fit(X_train, y_train)\r\n",
        "  # make a prediction for X_val\r\n",
        "  prediction = knn.predict(X_val)\r\n",
        "\r\n",
        "  # append the prediction into data collection vectors\r\n",
        "  c_total_predicted_labels.append(prediction[0][0])\r\n",
        "  cd_predicted_labels.append(prediction[0][1])\r\n",
        "  pb_predicted_labels.append(prediction[0][2])\r\n",
        "  # append the true labels (y_val) to data collection vectors\r\n",
        "  c_total_true_labels.append(y_val.iat[0,0])\r\n",
        "  cd_true_labels.append(y_val.iat[0,1])\r\n",
        "  pb_true_labels.append(y_val.iat[0,2])\r\n",
        "\r\n",
        "# calculate the concordance index for all vector pairs\r\n",
        "c_index_c_total = cindex(c_total_true_labels, c_total_predicted_labels)\r\n",
        "c_index_cd = cindex(cd_true_labels, cd_predicted_labels)\r\n",
        "c_index_pb = cindex(pb_true_labels, pb_predicted_labels)\r\n",
        "\r\n",
        "# print them\r\n",
        "print(\"Concordance index for c_total: \", c_index_c_total)\r\n",
        "print(\"Concordance index for Cd: \",c_index_cd)\r\n",
        "print(\"Concordance index for Pb: \",c_index_pb)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Concordance index for c_total:  0.9099991312657458\n",
            "Concordance index for Cd:  0.8961456549880987\n",
            "Concordance index for Pb:  0.8716749488453669\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3yKzJKzqbRGy"
      },
      "source": [
        "## Results for Leave-Replicas-Out cross-validation\r\n",
        "This time I'll use a different way to split the data, in hopes of getting more reliable results. I'll make splits so that all replicas are in one validation set, and then make predictions for all of them at the same time. Concordance index is calculated the same way as in LOO."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSJMrOKhbRGy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cef098e0-9e7c-4315-b374-36853181f260"
      },
      "source": [
        "# we'll do exactly the same thing as before, but with different splits\r\n",
        "# and we make more thanone prediction each time, either 3 or 4\r\n",
        "# depending on the data point (how many replicas it has)\r\n",
        "\r\n",
        "# make data collection vectors\r\n",
        "c_total_predicted_labels = []\r\n",
        "cd_predicted_labels = []\r\n",
        "pb_predicted_labels = []\r\n",
        "\r\n",
        "c_total_true_labels = []\r\n",
        "cd_true_labels = []\r\n",
        "pb_true_labels = []\r\n",
        "\r\n",
        "# droplist tells us if we have already included a datapoint in a\r\n",
        "# validation set; we want each datapoint to be in one validation set,\r\n",
        "# so that we do not make multiple predictions for one datapoint\r\n",
        "# droplist is updated everytime we make a train-test split\r\n",
        "droplist = []\r\n",
        "\r\n",
        "# loop over data\r\n",
        "for i in range(len(water_data)):\r\n",
        "  \r\n",
        "  # if this index has not been in a validation set yet\r\n",
        "  if i not in droplist:\r\n",
        "    \r\n",
        "    # make split with LRO folds\r\n",
        "    X_train, X_val, y_train, y_val, droplist = LRO_folds(X,y,i,droplist)\r\n",
        "\r\n",
        "    # train knn similarly to before, fit, and predict for X_val\r\n",
        "    knn = KNeighborsRegressor(n_neighbors=3, metric='euclidean')\r\n",
        "    knn.fit(X_train, y_train)\r\n",
        "    prediction = knn.predict(X_val)\r\n",
        "    \r\n",
        "    # append all 3 or 4 predictions to the data collection vectors\r\n",
        "    c_total_predicted_labels.extend(prediction[:,0])\r\n",
        "    cd_predicted_labels.extend(prediction[:,1])\r\n",
        "    pb_predicted_labels.extend(prediction[:,2])\r\n",
        "\r\n",
        "    # here the same but with the real labels\r\n",
        "    c_total_true_labels.extend(y_val['c_total'].tolist())\r\n",
        "    cd_true_labels.extend(y_val['Cd'].tolist())\r\n",
        "    pb_true_labels.extend(y_val['Pb'].tolist())\r\n",
        "\r\n",
        "\r\n",
        "# calculate the concordance index similarly as before\r\n",
        "c_index_c_total = cindex(c_total_true_labels, c_total_predicted_labels)\r\n",
        "c_index_cd = cindex(cd_true_labels, cd_predicted_labels)\r\n",
        "c_index_pb = cindex(pb_true_labels, pb_predicted_labels)\r\n",
        "\r\n",
        "# print results\r\n",
        "print(\"Concordance index for c_total: \", c_index_c_total)\r\n",
        "print(\"Concordance index for Cd: \", c_index_cd)\r\n",
        "print(\"Concordance index for Pb: \", c_index_pb)\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Concordance index for c_total:  0.8091390843540961\n",
            "Concordance index for Cd:  0.7578402305090408\n",
            "Concordance index for Pb:  0.7649809997076878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzyWp5dQbRGy"
      },
      "source": [
        "## Interpretation of results\n",
        "#### Answer the following questions based on the results obtained\n",
        "- Which cross-validation approach had more optimistic results?\n",
        "- Which cross-validation generalize better on unseen data? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t_DLufZlpEdJ"
      },
      "source": [
        "More optimistic results were given by LOO:\r\n",
        "\r\n",
        "Concordance index for c_total:  0.9099991312657458 \\\r\n",
        "Concordance index for Cd:  0.8961456549880987 \\\r\n",
        "Concordance index for Pb:  0.8716749488453669. \\\r\n",
        "\r\n",
        "With LRO, the results were about 10 %-points lower:\r\n",
        "\r\n",
        "Concordance index for c_total:  0.8091390843540961 \\\r\n",
        "Concordance index for Cd:  0.7578402305090408 \\\r\n",
        "Concordance index for Pb:  0.7649809997076878. \\\r\n",
        "\r\n",
        "These values seem to be really close to the values obtained in the lecture material (the graphs with k = 3 seem to have similar values).\r\n",
        "\r\n",
        "When we do cross validation with LOO, replicated points in the data set cause data leakage. While we have a quite similar (same labels, almost same Mod1-3 values) in the training set, making predictions on the test set is much easier compared to the situation, where the test set is completely unseen data. We avoid this problem with LRO, because similar data points are in the same test set. Thus LRO cross validation generalizes better on unseen data."
      ]
    }
  ]
}